# Explore OpenAI Gym Environments
The goal of the project was to work with value function approximation algorithms, to explore OpenAI Gym environments. We have implemented Deep Q-learning (DQN) following DeepMindâ€™s paper that explains how reinforcement learning algorithms can learn to play Atari from raw pixels. In the next partwe have implemented an improvement to the DQN algorithm. The purpose of this assignment is to understand the benefits of approximation methods, the role of deep neural networks as well as some of the techniques used in practice to stabilize training and to achieve better performance. We will train our networks on the grid-world and OpenAI gym environments.

We have experimented with three environments in total:
1. Custom Grid World Environment
2. CartPole-v1
3. MountainCar-v0

For all three environments we have tried solving them using `Deep Q-Network` and `Double Deep N-Network`. We have documented the whole projects with the results in the `Report.pdf` file represent in the repository.

_Note: While working with the jupyter notebook, the absolute path for weights might not work as after the project was finished we have reorganized the files into different folders for convenience. To run the code please make sure the paths are correct._

**Collaborators:**
- Anuja Katkar
- Sagar Thacker
